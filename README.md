# ç’°å¢ƒæ§‹ç¯‰

## Google colaboratoryã®æº–å‚™

- [Google colaboratory](https://colab.research.google.com/)ã«ã‚¢ã‚¯ã‚»ã‚¹
- å³ä¸‹ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’æ–°è¦ä½œæˆã‚’ã‚¯ãƒªãƒƒã‚¯
- Python3ã®æ–°ã—ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’é¸æŠ
- ä¸Šãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‹ã‚‰ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ã‚’ã‚¯ãƒªãƒƒã‚¯
- ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ã«GPUã‚’é¸æŠã—ã¦ä¿å­˜

## Kerasã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ä»Šå›ã¯Kerasã‚’ä½¿ã„ã¾ã™ã€‚ç†ç”±ã¨ã—ã¦ã¯

- æ›¸ãæ–¹ãŒTensorflowã«æ¯”ã¹ç°¡å˜ï¼ˆã¾ã‚Tensorflowã‚‚ã„ã¤ã‹ã‚„ã‚‹ã‘ã©ãªï¼‰
- Tensorflowã«å¸åã•ã‚Œã¦ã„ã‚‹ã®ã§å¿œç”¨ãŒåŠ¹ã
- Kerasã§æ…£ã‚Œã¦ã‹ã‚‰Tensorflowä½¿ã†ã¨è‰¯ã„ã¨æ€ã„ã¾ã™
- æ­£ç›´ãƒã‚¤ãƒ‘ãƒ©ãƒ‘ãƒ©ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã®ã§ã‚‚ã‚ã‚“ã©ãã•ã„ã®ã«ãƒ¢ãƒ‡ãƒ«ãã¡ã‚“ã¨æ›¸ãã®ã‚ã‚“ã©ãã•ã„
- ã¾ã‚Kerasã§ç‰©è¶³ã‚Šãªã„ãªã¨æ€ã†ã¨ãã¯ãã‚‹ï¼ˆã¯ãšï¼‰
- æ™‚é–“ãŒãªã„ï¼ˆä¸€ç•ªå¤§ãã„ï¼‰

ä»¥ä¸Šã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

ä»Šå›ã¯æ™‚é–“ãŒãªã„ï¼ˆæœªæ¥è¦–ï¼‰ã®ã§ã‚³ãƒ”ãƒšã—ã¦å‹•ãã‚ˆã†ã«ã—ã¦ã‚ã‚Šã¾ã™ã€‚
ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ä¸€ç•ªä¸Šã®ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã«

```
!mkdir ./result
!pip install -q keras
import keras
```
ã‚’å…¥åŠ›ã—ã¦[Shift+Enter]ã¾ãŸã¯ã‚»ãƒ«ã®å·¦ã®å†ç”Ÿãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ä¸‹ã•ã„

```
Using TensorFlow backend.
```

ã¨å‡ºåŠ›ã•ã‚Œã‚Œã°æ­£ã—ãimportã•ã‚Œã¦ã„ã¾ã™ã€‚

ä»Šå›ã¯LSTMã‚’ç”¨ã„ã¦siné–¢æ•°ï¼ˆæ™‚é–“ã‚ã£ãŸã‚‰ã‚‚ã†ã¡ã‚‡ã£ã¨è¤‡é›‘ãªã‚„ã¤ã‚‚ï¼‰ã®äºˆæ¸¬ã‚’ã•ã›ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

LSTMã£ã¦ã©ã†ãªã£ã¦ã‚“ã ã‚ˆï¼ˆå“²å­¦ï¼‰ã¨æ°—ã«ãªã‚‹æ–¹ã‚‚ã„ã¾ã™ã§ã—ã‚‡ã†ãŒèª¬æ˜ã™ã‚‹æ™‚é–“ãŒãªã„ã§ã™ï¼ˆãŸã¶ã‚“ï¼‰

å™›ã¿ç •ãã¾ãã£ã¦èª¬æ˜ã™ã‚‹ã¨LSTMã¯RNNã®ä¸€ç¨®ã§ã‚ã‚Šæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆex: æ³¢å‹•ã€ç‚ºæ›¿ã€å‹•ç”»ã€ãªã©ãªã©ï¼‰ã®ã‚¿ã‚¹ã‚¯
ã«å¯¾ã—ã¦ã‚ˆã„åŠ¹åŠ›ã‚’ç™ºæ®ã—ã¾ã™ã€‚

æ™‚é–“ã‚ã£ãŸã‚‰ã“ã®ã¸ã‚“ã‚‚èª¬æ˜ã™ã‚‹ğŸ˜ƒã€‚

## LSTMã®å­¦ç¿’

### å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªé¡ã‚’import

```
import os
import sys
import random
import math
import numpy as np
import matplotlib.pyplot as plt
from keras import optimizers, callbacks, initializers
from keras.models import Sequential, Model, load_model
from keras.layers import Input, Activation, Dropout, Flatten, Dense, LSTM
```

### å®šæ•°ã‚’å®šç¾©

```
# éš ã‚Œå±¤ã®æ•°
N_HIDDEN = 300
# ã‚¹ãƒ†ãƒƒãƒ—æ•°
LEN_SEQ  = 80
# ç‰¹å¾´ã®æ¬¡å…ƒæ•°
IN_NEUR  = 1
# ãƒãƒƒãƒã‚µã‚¤ã‚º
BATCH_NM = 256
# ã‚¨ãƒãƒƒã‚¯æ•°
EPOCH_NM = 1000
# ã‚µã‚¤ã‚¯ãƒ«ã‚ãŸã‚Šã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
STEPS_PER_CYCLE = 80
# ç”Ÿæˆã™ã‚‹ã‚µã‚¤ã‚¯ãƒ«æ•°
NUM_OF_CYCLE = 50

result_dir = './result/'
```

### LSTMãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°ã‚’å®šç¾©

```
def create_lstm_model():
    input_layer = Input(shape=(LEN_SEQ, IN_NEUR))
    lstm_out = LSTM(N_HIDDEN, input_shape=(LEN_SEQ, IN_NEUR), bias_initializer=initializers.Constant(value=(np.random.rand() / 10.0)), return_sequences=False)(input_layer)
    model_output = Dense(1, activation='linear')(lstm_out)
    model = Model(input_layer, model_output)
    model.compile(loss='mean_squared_error',
                  optimizer=optimizers.RMSprop())
    return model
```

### siné–¢æ•°ã‚’ä¸€å®šã‚µã‚¤ã‚¯ãƒ«ç”Ÿæˆã—ã¦ãã‚Œã‚’åˆ†å‰²ã—ã¦è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ

```
def mk_sin_traindata():
    fx_data= [math.sin(x * (2 * math.pi / STEPS_PER_CYCLE)) for x in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE)]

    x_data = []
    y_data = []
    for i in range(0, len(fx_data)-LEN_SEQ):
        x_data.append(np.array(fx_data[i:i+LEN_SEQ]).reshape(LEN_SEQ, 1))
        y_data.append(fx_data[i+LEN_SEQ])

    if len(x_data) == len(y_data):
        x_data = np.array(x_data)
        y_data = np.array(y_data)
        p = np.random.permutation(len(x_data))
        x_data = x_data[p]
        y_data = y_data[p]

        return x_data, y_data
```

### callbackã®å®šç¾©ï¼ˆKerasã§ã¯epochãŒçµ‚ã‚ã‚‹ã”ã¨ã«é–¢æ•°ã‚’å‘¼ã³å‡ºã›ã‚‹ï¼‰

ä»Šå›ã¯

- ãƒ¢ãƒ‡ãƒ«ã‚’epochæ¯ã«è‡ªå‹•çš„ã«ä¿å­˜ã—ã¦ãã‚Œã‚‹é–¢æ•°
- ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ãŒä¼¸ã³ãªããªã£ãŸã‚‰å­¦ç¿’ã‚’é€”ä¸­ã§æ‰“ã¡åˆ‡ã‚‹é–¢æ•°

ã‚’å‘¼ã³å‡ºã™

```
cp_cb = callbacks.ModelCheckpoint(
    filepath = './result/model{epoch:03d}-loss{loss:.3f}-vloss{val_loss:.3f}.h5',
    monitor='val_loss',
    verbose=1,
    save_best_only=True,
    save_weights_only=False,
    mode='auto')

es_cb = callbacks.EarlyStopping(
    monitor='val_loss',
    patience=20,
    verbose=0,
    mode='auto')
```

### ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦å­¦ç¿’ã‚’é–‹å§‹

```
np.random.seed(0)
model = create_lstm_model()

x_train , y_train = mk_traindata()

model.fit(
    x=x_train,
    y=y_train,
    batch_size=BATCH_NM,
    epochs=EPOCH_NM,
    verbose=1,
    callbacks=[cp_cb, es_cb],
    validation_split=0.3,
    shuffle=False)
```

## æ¤œè¨¼

ã„ã„æ„Ÿã˜ã«å­¦ç¿’ãŒã§ããŸã‚‰

```
!ls ./result
```

ã‚’å®Ÿè¡Œã—ã¦val_lossãŒä¸€ç•ªå°ã•ã„ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã‹ã‚‰
ä¸‹ã®æ¤œè¨¼ç”¨é–¢æ•°ã‚’å®šç¾©

```
model_file = "./result/ã‚³ãƒ”ãƒ¼ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«å"

def validation():
    model = load_model(os.path.join(model_file))
    x = [i for i in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE+ 200)]

    # æ¤œè¨¼ç”¨ã®ç­”ãˆ
    val_y = [math.sin(x * (2 * math.pi / STEPS_PER_CYCLE)) for x in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE+ 200)]
    val_y = val_y[-200:]

    predict = [math.sin(x * (2 * math.pi / STEPS_PER_CYCLE)) for x in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE)]
    for i in range(0, 200):
        data = np.array([np.array(predict[-LEN_SEQ:]).reshape(LEN_SEQ, 1)])

        pred = model.predict(data)[0]

        predict = np.append(predict, pred)

    predict = predict[-200:]
    x = x[-200:]

    plt.plot(x, val_y, color="red")
    plt.plot(x, predict, color="blue")
    plt.show
```

æ¤œè¨¼ç”¨é–¢æ•°ã‚’å®Ÿè¡Œ

ä»Šå›ã¯200ã‚¹ãƒ†ãƒƒãƒ—å‡ºåŠ›ã•ã›ã¦ã¿ã‚‹

èµ¤è‰²ãŒæ­£è§£ã€é’è‰²ãŒä»Šå›å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã®çµæœ


```
validation()
```

## ã‚ã‚“ã©ãã›ãˆã‚ˆé–¢æ•°ã¨ã‹å®šæ•°éƒ¨åˆ†æœ€åˆã«å…¨éƒ¨ã‚³ãƒ”ãƒ¼ã•ã›ã‚ã‚„ã¨ã„ã†éœ€è¦

### ãƒ¢ãƒ‡ãƒ«ãƒ»å­¦ç¿’éƒ¨åˆ†

```
!mkdir ./result
!pip install -q keras

import os
import sys
import random
import math
import numpy as np
import matplotlib.pyplot as plt
from keras import optimizers, callbacks, initializers
from keras.models import Sequential, Model, load_model
from keras.layers import Input, Activation, Dropout, Flatten, Dense, LSTM

# éš ã‚Œå±¤ã®æ•°
N_HIDDEN = 300
# ã‚¹ãƒ†ãƒƒãƒ—æ•°
LEN_SEQ  = 80
# ç‰¹å¾´ã®æ¬¡å…ƒæ•°
IN_NEUR  = 1
# ãƒãƒƒãƒã‚µã‚¤ã‚º
BATCH_NM = 256
# ã‚¨ãƒãƒƒã‚¯æ•°
EPOCH_NM = 1000
# ã‚µã‚¤ã‚¯ãƒ«ã‚ãŸã‚Šã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
STEPS_PER_CYCLE = 80
# ç”Ÿæˆã™ã‚‹ã‚µã‚¤ã‚¯ãƒ«æ•°
NUM_OF_CYCLE = 50

result_dir = './result/'

def create_lstm_model():
    input_layer = Input(shape=(LEN_SEQ, IN_NEUR))
    lstm_out = LSTM(N_HIDDEN, input_shape=(LEN_SEQ, IN_NEUR), bias_initializer=initializers.Constant(value=(np.random.rand() / 10.0)), return_sequences=False)(input_layer)
    model_output = Dense(1, activation='linear')(lstm_out)
    model = Model(input_layer, model_output)
    model.compile(loss='mean_squared_error',
                  optimizer=optimizers.RMSprop())
    return model

def mk_traindata():
    fx_data= [math.sin(x * (2 * math.pi / STEPS_PER_CYCLE)) for x in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE)]

    x_data = []
    y_data = []
    for i in range(0, len(fx_data)-LEN_SEQ):
        x_data.append(np.array(fx_data[i:i+LEN_SEQ]).reshape(LEN_SEQ, 1))
        y_data.append(fx_data[i+LEN_SEQ])

    if len(x_data) == len(y_data):
        x_data = np.array(x_data)
        y_data = np.array(y_data)
        p = np.random.permutation(len(x_data))
        x_data = x_data[p]
        y_data = y_data[p]

        return x_data, y_data

np.random.seed(0)
model = create_lstm_model()

cp_cb = callbacks.ModelCheckpoint(
    filepath = './result/model{epoch:03d}-loss{loss:.3f}-vloss{val_loss:.3f}.h5',
    monitor='val_loss',
    verbose=1,
    save_best_only=True,
    save_weights_only=False,
    mode='auto')

es_cb = callbacks.EarlyStopping(
    monitor='val_loss',
    patience=20,
    verbose=0,
    mode='auto')

x_train , y_train = mk_traindata()

model.fit(
    x=x_train,
    y=y_train,
    batch_size=BATCH_NM,
    epochs=EPOCH_NM,
    verbose=1,
    callbacks=[cp_cb, es_cb],
    validation_split=0.3,
    shuffle=False)
```

### æ¤œè¨¼ç”¨é–¢æ•°ã®éƒ¨åˆ†

```
model_file = "./result/ã‚³ãƒ”ãƒ¼ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«å"

def validation():
    model = load_model(os.path.join(model_file))
    x = [i for i in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE+ 200)]

    # æ¤œè¨¼ç”¨ã®ç­”ãˆ
    val_y = [math.sin(x * (2 * math.pi / STEPS_PER_CYCLE)) for x in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE+ 200)]
    val_y = val_y[-200:]

    predict = [math.sin(x * (2 * math.pi / STEPS_PER_CYCLE)) for x in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE)]
    for i in range(0, 200):
        data = np.array([np.array(predict[-LEN_SEQ:]).reshape(LEN_SEQ, 1)])

        pred = model.predict(data)[0]

        predict = np.append(predict, pred)

    predict = predict[-200:]
    x = x[-200:]

    plt.plot(x, val_y, color="red")
    plt.plot(x, predict, color="blue")
    plt.show
```

```
validation()
```

## ãŠã¾ã‘

æ™‚é–“ä½™ã£ãŸã‚‰ã‚‚ã†ã¡ã‚‡ã£ã¨è¤‡é›‘ãªé–¢æ•°ã‚‚å­¦ç¿’ã•ã›ã¦ã¿ã‚ˆã†ï¼ˆé©å½“ï¼‰

æ–°ã—ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’é–‹ã„ã¦traindata()ã¨validation()ã¨ã‚µã‚¤ã‚¯ãƒ«æ•°ã ã‘ã‚’ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰ãˆã‚‹

ã“ã‚Œã‚’å®Ÿè¡Œã—çµ‚ã‚ã£ãŸã‚‰fit()ã—ã¦ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã—ã¦ã‹ã‚‰validation()ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘

```
# ã‚µã‚¤ã‚¯ãƒ«ã‚ãŸã‚Šã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
STEPS_PER_CYCLE = 80
# ç”Ÿæˆã™ã‚‹ã‚µã‚¤ã‚¯ãƒ«æ•°
NUM_OF_CYCLE = 200

def mk_traindata():
    fx_data= [3 * math.sin(5 * x * (2 * math.pi / STEPS_PER_CYCLE)) - 5 * math.cos(3 * x * (2 * math.pi / STEPS_PER_CYCLE)) for x in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE)]

    x_data = []
    y_data = []
    for i in range(0, len(fx_data)-LEN_SEQ):
        x_data.append(np.array(fx_data[i:i+LEN_SEQ]).reshape(LEN_SEQ, 1))
        y_data.append(fx_data[i+LEN_SEQ])

    if len(x_data) == len(y_data):
        x_data = np.array(x_data)
        y_data = np.array(y_data)
        p = np.random.permutation(len(x_data))
        x_data = x_data[p]
        y_data = y_data[p]

        return x_data, y_data

def validation():
    model = load_model(os.path.join(model_file))
    x = [i for i in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE+ 200)]

    # æ¤œè¨¼ç”¨ã®ç­”ãˆ
    val_y = [3 * math.sin(5 * x * (2 * math.pi / STEPS_PER_CYCLE)) - 5 * math.cos(3 * x * (2 * math.pi / STEPS_PER_CYCLE)) for x in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE+ 200)]
    val_y = val_y[-200:]

    predict = [3 * math.sin(5 * x * (2 * math.pi / STEPS_PER_CYCLE)) - 5 * math.cos(3 * x * (2 * math.pi / STEPS_PER_CYCLE)) for x in range(0, NUM_OF_CYCLE * STEPS_PER_CYCLE)]
    for i in range(0, 200):
        data = np.array([np.array(predict[-LEN_SEQ:]).reshape(LEN_SEQ, 1)])

        pred = model.predict(data)[0]
        if i < 100:
            print(pred)

        predict = np.append(predict, pred)

    predict = predict[-200:]
    x = x[-200:]

    plt.plot(x, val_y, color="red")
    plt.plot(x, predict, color="blue")
    plt.show
```

## çµæœ

ã†ã¾ãã„ã‘ã°ã“ã‚“ãªæ„Ÿã˜ãªå‡ºåŠ›ãŒå¾—ã‚‰ã‚Œã‚‹ã¯ãš

### sinæ³¢

![sin_rmsprop](https://user-images.githubusercontent.com/33972190/40005483-fa0be122-57d2-11e8-8884-872595820be5.png)

### 3sin5x-5cos3x

![sincos_cycle200](https://user-images.githubusercontent.com/33972190/40005486-fc66d0c6-57d2-11e8-9198-e035ddeb30c9.png)